"""
AI Expert System - Admin UI (å¾Œå°ç®¡ç†ä»‹é¢)
Port: 8501 (é è¨­)

åŠŸèƒ½ï¼š
- æ–‡ä»¶ä¸Šå‚³èˆ‡è§£æï¼ˆæ”¯æ´å››ç¨®é¡å‹ï¼‰
- è³‡æ–™åº«ç®¡ç†èˆ‡çµ±è¨ˆ
- Token ä½¿ç”¨ç›£æ§
- ç³»çµ±è¨­å®š
"""

import streamlit as st
import os
from datetime import datetime
from core import database, ingestion
from core import ingestion_v3  # v3.0 æ–°æ¨¡çµ„
from core import search  # v3.0 é‡æ§‹å¾Œçš„ search æ¨¡çµ„
import config

# é é¢è¨­å®š
st.set_page_config(
    page_title="AI Expert System - ç®¡ç†å¾Œå°",
    page_icon="âš™ï¸",
    layout="wide"
)

st.title("âš™ï¸ AI Expert System - ç®¡ç†å¾Œå°")
st.markdown("---")

# å´é‚Šæ¬„ï¼šç³»çµ±è³‡è¨Š
with st.sidebar:
    st.header("ğŸ“Š ç³»çµ±è³‡è¨Š")
    
    # è³‡æ–™åº«çµ±è¨ˆ
    db_stats = database.get_document_stats()
    st.metric("ç¸½æ–‡ä»¶æ•¸", db_stats['total_documents'])
    
    st.subheader("æ–‡ä»¶åˆ†é¡")
    for doc_type, count in db_stats.get('by_type', {}).items():
        st.write(f"- {doc_type}: {count} ä»½")
    
    # Token çµ±è¨ˆ
    token_stats = database.get_token_stats()
    st.subheader("Token ä½¿ç”¨")
    st.metric("ç¸½ä½¿ç”¨é‡", f"{token_stats['total_tokens']:,} tokens")
    
    st.markdown("---")
    st.caption(f"Database: {config.DB_PATH}")


# ä¸»è¦å…§å®¹å€ï¼šTab åˆ†é 
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“¤ æ–‡ä»¶ä¸Šå‚³",
    "ğŸ—‚ï¸ è³‡æ–™åº«ç®¡ç†",
    "ğŸ“ˆ Token ç›£æ§",
    "âš™ï¸ ç³»çµ±è¨­å®š"
])

# ========== Tab 1: æ–‡ä»¶ä¸Šå‚³ ==========
with tab1:
    st.header("æ–‡ä»¶ä¸Šå‚³èˆ‡è§£æ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("é¸æ“‡æ–‡ä»¶é¡å‹")
        file_type = st.selectbox(
            "æ–‡ä»¶åˆ†é¡",
            options=['knowledge', 'training', 'procedure', 'troubleshooting'],
            format_func=lambda x: {
                'knowledge': 'ğŸ“š çŸ¥è­˜åº«',
                'training': 'ğŸ“ æ•™è‚²è¨“ç·´',
                'procedure': 'ğŸ“‹ æ—¥å¸¸æ‰‹é †',
                'troubleshooting': 'ğŸ”§ ç•°å¸¸è§£æ'
            }[x]
        )
        
        st.info({
            'knowledge': 'é©åˆæŠ€è¡“æ–‡ä»¶ã€æ‰‹å†Šã€æ•™ç§‘æ›¸ç­‰æœ‰ç« ç¯€çµæ§‹çš„å…§å®¹',
            'training': 'é©åˆåŸ¹è¨“æ•™æã€èª²ç¨‹è¬›ç¾©',
            'procedure': 'é©åˆ SOPã€æ“ä½œæ‰‹é †ã€æµç¨‹èªªæ˜',
            'troubleshooting': 'é©åˆç•°å¸¸å ±å‘Šã€8D å ±å‘Šã€ç¶­ä¿®è¨˜éŒ„'
        }[file_type])
        
        doc_dir = st.text_input(
            "æ–‡ä»¶è³‡æ–™å¤¾è·¯å¾‘",
            value="",
            placeholder="ä¾‹å¦‚: D:/Documents/SOP"
        )
        
        file_extensions = st.multiselect(
            "æ”¯æ´çš„æª”æ¡ˆæ ¼å¼",
            options=['.pptx', '.md', '.txt', '.pdf'],
            default=['.pptx', '.md', '.txt']
        )
    
    with col2:
        st.subheader("è™•ç†é¸é …")
        
        # å–å¾—ç³»çµ±é è¨­è¨­å®š
        current_config = config.get_api_config()
        default_analysis_mode = current_config.get('analysis_mode', 'auto')
        default_text_model = current_config.get('model_text', 'gpt-4o-mini')
        default_vision_model = current_config.get('model_vision', 'gpt-4o')

        # v3.0 æ–°å¢: Analysis Mode é¸æ“‡
        st.write("**ğŸ“Š åˆ†ææ¨¡å¼ (é è¨­å€¼ä¾†è‡ªç³»çµ±è¨­å®š)**")
        
        analysis_mode_options = ["text_only", "vision", "auto"]
        # ç¢ºä¿é è¨­å€¼åœ¨é¸é …ä¸­
        if default_analysis_mode not in analysis_mode_options:
            analysis_mode_options.append(default_analysis_mode)
            
        analysis_mode = st.radio(
            "Analysis Mode",
            options=analysis_mode_options,
            index=analysis_mode_options.index(default_analysis_mode),
            format_func=lambda x: {
                "text_only": "ğŸ’° ç´”æ–‡å­— (ç¶“æ¿Ÿ)",
                "vision": "ğŸ‘ï¸ åœ–æ–‡åˆ†æ (é«˜éš)",
                "auto": "ğŸ¤– è‡ªå‹•åˆ¤æ–·"
            }.get(x, x),
            horizontal=True
        )
        
        # v3.0 æ–°å¢: æ¨¡å‹é¸æ“‡
        col_model1, col_model2 = st.columns(2)
        with col_model1:
            # å®šç¾©é¸é … (èˆ‡ç³»çµ±è¨­å®šä¸€è‡´)
            text_model_options = [
                "gpt-4o-mini", "gpt-4.1-mini", "gemini-2.5-flash-lite", 
                "gemini-2.5-flash", "gpt-4o", "gpt-4.1", "gemini-2.5-pro"
            ]
            
            # ç¢ºä¿é è¨­å€¼åœ¨é¸é …ä¸­
            if default_text_model and default_text_model not in text_model_options:
                text_model_options.append(default_text_model)
                
            text_model = st.selectbox(
                "è§£ææ¨¡å‹ (Text)",
                options=text_model_options,
                index=text_model_options.index(default_text_model) if default_text_model in text_model_options else 0,
                format_func=lambda x: f"{x} {config.MODEL_COST_LABELS.get(x, '')}"
            )
        
        with col_model2:
            # å®šç¾©é¸é …
            vision_model_options = ["gpt-4o", "gemini-2.5-flash", "gemini-2.5-pro", "gpt-4.1"]
            
            # ç¢ºä¿é è¨­å€¼åœ¨é¸é …ä¸­
            if default_vision_model and default_vision_model not in vision_model_options:
                vision_model_options.append(default_vision_model)

            vision_model = st.selectbox(
                "è¦–è¦ºæ¨¡å‹ (Vision)",
                options=vision_model_options,
                index=vision_model_options.index(default_vision_model) if default_vision_model in vision_model_options else 0,
                format_func=lambda x: f"{x} {config.MODEL_COST_LABELS.get(x, '')}"
            ) if analysis_mode in ["vision", "auto"] else None
        
        st.write("**è™•ç†æµç¨‹ (v3.0)**:")
        st.write("1. è®€å–æª”æ¡ˆå…§å®¹")
        st.write("2. AI è§£æ â†’ æ¨™æº–åŒ–åˆ‡ç‰‡")
        st.write("3. å‘é‡åŒ–æ‰€æœ‰åˆ‡ç‰‡")
        st.write("4. å¯«å…¥è³‡æ–™åº« (Parent-Child)")
        
        # æª¢æŸ¥ API æ˜¯å¦å·²è¨­å®š
        api_config = config.get_api_config()
        if not api_config['api_key']:
            st.error("âš ï¸ è«‹å…ˆåœ¨ã€Œç³»çµ±è¨­å®šã€é é¢è¨­å®š API Key")
        else:
            st.info(f"âœ… API å·²è¨­å®š: {api_config['base_url']}")
    
    if st.button("ğŸš€ é–‹å§‹è™•ç†", type="primary", use_container_width=True):
        # æª¢æŸ¥ API è¨­å®š
        api_config = config.get_api_config()
        if not api_config['api_key']:
            st.error("âŒ è«‹å…ˆåœ¨ã€Œç³»çµ±è¨­å®šã€é é¢è¨­å®š API Key!")
        elif not doc_dir or not os.path.exists(doc_dir):
            st.error("è«‹è¼¸å…¥æœ‰æ•ˆçš„è³‡æ–™å¤¾è·¯å¾‘")
        else:
            with st.spinner(f"æ­£åœ¨è™•ç† {file_type} æ–‡ä»¶..."):
                # å»ºç«‹é€²åº¦æ¢
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(current, total, message):
                    progress_bar.progress(current / total)
                    status_text.text(f"[{current}/{total}] {message}")
                
                # åŸ·è¡Œè™•ç† (v3.0)
                stats = ingestion_v3.process_directory_v3(
                    doc_dir=doc_dir,
                    doc_type=file_type.capitalize(),  # v3.0 ä½¿ç”¨å¤§å¯«
                    analysis_mode=analysis_mode,
                    text_model=text_model,
                    vision_model=vision_model,
                    file_extensions=file_extensions,
                    progress_callback=lambda msg: status_text.text(msg)
                )
                
                # é¡¯ç¤ºçµæœ
                st.success("âœ… v3.0 è™•ç†å®Œæˆï¼")
                
                col_a, col_b, col_c = st.columns(3)
                col_a.metric("ç¸½æª”æ¡ˆ", stats['processed'])
                col_b.metric("æˆåŠŸ", stats['success'])
                col_c.metric("éŒ¯èª¤æ•¸", len(stats['errors']))
                
                if stats['errors']:
                    with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"):
                        for error in stats['errors']:
                            st.error(f"{error['file']}: {error['error']}")

# ========== Tab 2: è³‡æ–™åº«ç®¡ç† ==========
with tab2:
    st.header("è³‡æ–™åº«ç®¡ç†")
    
    # æœå°‹åŠŸèƒ½
    st.subheader("ğŸ” æœå°‹æ–‡ä»¶")
    search_col1, search_col2 = st.columns([3, 1])
    
    with search_col1:
        search_query = st.text_input("æœå°‹é—œéµå­—", placeholder="è¼¸å…¥é—œéµå­—...")
    
    with search_col2:
        search_types = st.multiselect(
            "é™å®šé¡å‹",
            options=['knowledge', 'training', 'procedure', 'troubleshooting'],
            default=[]
        )
    
    if search_query:
        results = search.search_documents_v2(
            query=search_query,
            file_types=search_types if search_types else None,
            fuzzy=True,
            top_k=20
        )
        
        st.write(f"æ‰¾åˆ° **{len(results)}** ç­†çµæœ")
        
        for doc in results:
            with st.expander(f"ğŸ“„ {doc['file_name']} ({doc['file_type']})"):
                st.write(f"**ID**: {doc['id']}")
                if doc.get('author'):
                    st.write(f"**ä½œè€…**: {doc['author']}")
                st.write(f"**ä¸Šå‚³æ™‚é–“**: {datetime.fromtimestamp(doc['upload_time']).strftime('%Y-%m-%d %H:%M')}")
                st.write(f"**é è¦½**: {doc.get('preview', '')}")
                
                if st.button(f"åˆªé™¤", key=f"del_{doc['id']}"):
                    if database.delete_document(doc['id']):
                        st.success("å·²åˆªé™¤")
                        st.rerun()
                    else:
                        st.error("åˆªé™¤å¤±æ•—")
    
    st.markdown("---")
    
    # çµ±è¨ˆè³‡è¨Š
    st.subheader("ğŸ“Š è³‡æ–™çµ±è¨ˆ")
    stats = database.get_document_stats()
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ç¸½æ–‡ä»¶æ•¸", stats['total_documents'])
    
    with col2:
        st.write("**åˆ†é¡åˆ†ä½ˆ**")
        for doc_type, count in stats.get('by_type', {}).items():
            st.write(f"- {doc_type}: {count}")

# ========== Tab 3: Token ç›£æ§ ==========
with tab3:
    st.header("Token ä½¿ç”¨ç›£æ§")
    
    # æ™‚é–“ç¯„åœé¸æ“‡
    time_range = st.selectbox(
        "æ™‚é–“ç¯„åœ",
        options=[None, 1, 7, 30],
        format_func=lambda x: "å…¨éƒ¨" if x is None else f"æœ€è¿‘ {x} å¤©"
    )
    
    token_stats = database.get_token_stats(days=time_range)
    
    # ç¸½è¦½
    col1, col2, col3 = st.columns(3)
    col1.metric("ç¸½ Token", f"{token_stats['total_tokens']:,}")
    col2.metric("Input Tokens", f"{token_stats['total_prompt_tokens']:,}")
    col3.metric("Output Tokens", f"{token_stats['total_completion_tokens']:,}")
    
    st.markdown("---")
    
    # æŒ‰æ“ä½œé¡å‹çµ±è¨ˆ
    st.subheader("æŒ‰æ“ä½œé¡å‹")
    by_op = token_stats.get('by_operation', {})
    if by_op:
        for op, count in by_op.items():
            st.write(f"- {op}: {count:,} tokens")
    
    st.markdown("---")
    
    # Top 10 æª”æ¡ˆ
    st.subheader("Top 10 æ¶ˆè€—æª”æ¡ˆ")
    by_file = token_stats.get('by_file', [])
    if by_file:
        for item in by_file[:10]:
            st.write(f"- {item['file_name']}: {item['total_tokens']:,} tokens")
    
    st.markdown("---")
    
    # æœ€è¿‘ä½¿ç”¨è¨˜éŒ„
    st.subheader("æœ€è¿‘ 20 ç­†è¨˜éŒ„")
    recent = token_stats.get('recent_usage', [])
    if recent:
        for record in recent[:20]:
            timestamp = datetime.fromtimestamp(record['timestamp']).strftime('%Y-%m-%d %H:%M:%S')
            st.text(f"{timestamp} | {record['operation']} | {record['file_name'] or 'N/A'} | {record['total_tokens']} tokens")

# ========== Tab 4: ç³»çµ±è¨­å®š ==========
with tab4:
    st.header("ç³»çµ±è¨­å®š")
    
    st.subheader("ğŸ”‘ API è¨­å®š")
    st.info("è«‹è¼¸å…¥æ‚¨çš„ OpenAI API ç›¸å®¹æœå‹™çš„è¨­å®š")
    
    # å–å¾—ç•¶å‰è¨­å®š
    current_config = config.get_api_config()
    
    col1, col2 = st.columns(2)
    
    with col1:
        new_api_key = st.text_input(
            "API Key",
            value=current_config['api_key'],
            type="password",
            help="æ‚¨çš„ OpenAI API Key æˆ–ç›¸å®¹æœå‹™çš„ API Key"
        )
        
        # å®šç¾©å¯ç”¨æ¨¡å‹æ¸…å–® (ä¾†è‡ª model_pricing_comparison.md)
        vision_model_options = [
            "gpt-4o", 
            "gemini-2.5-flash", 
            "gemini-2.5-pro", 
            "gpt-4.1"
        ]
        
        # ç¢ºä¿ç•¶å‰è¨­å®šçš„å€¼åœ¨é¸é …ä¸­ï¼Œå¦‚æœä¸åœ¨å‰‡åŠ å…¥
        current_vision = current_config['model_vision']
        if current_vision and current_vision not in vision_model_options:
            vision_model_options.append(current_vision)
            
        new_model_vision = st.selectbox(
            "Vision æ¨¡å‹åç¨±",
            options=vision_model_options,
            index=vision_model_options.index(current_vision) if current_vision in vision_model_options else 0,
            help="æ”¯æ´åœ–ç‰‡åˆ†æçš„æ¨¡å‹ (å»ºè­°: gpt-4o)"
        )
    
    with col2:
        new_base_url = st.text_input(
            "Base URL",
            value=current_config['base_url'],
            help="API ç«¯é» URL,ä¾‹å¦‚ https://api.openai.com/v1"
        )
        
        # å®šç¾©å¯ç”¨æ¨¡å‹æ¸…å–® (ä¾†è‡ª model_pricing_comparison.md)
        text_model_options = [
            "gpt-4o-mini",
            "gpt-4.1-mini", 
            "gemini-2.5-flash-lite",
            "gemini-2.5-flash",
            "gpt-4o", 
            "gpt-4.1", 
            "gemini-2.5-pro"
        ]
        
        # ç¢ºä¿ç•¶å‰è¨­å®šçš„å€¼åœ¨é¸é …ä¸­
        current_text = current_config['model_text']
        if current_text and current_text not in text_model_options:
            text_model_options.append(current_text)
            
        new_model_text = st.selectbox(
            "Text æ¨¡å‹åç¨±",
            options=text_model_options,
            index=text_model_options.index(current_text) if current_text in text_model_options else 0,
            help="ç´”æ–‡å­—æ¨¡å‹ (å»ºè­°: gpt-4o-mini æˆ– gemini-2.5-flash-lite)"
        )
        
    # åˆ†ææ¨¡å¼è¨­å®š (v3.0)
    st.markdown("---")
    st.subheader("ğŸ“Š é è¨­åˆ†ææ¨¡å¼")
    
    analysis_mode_options = ["text_only", "vision", "auto"]
    current_mode = current_config.get('analysis_mode', 'auto')
    
    new_analysis_mode = st.radio(
        "é¸æ“‡é è¨­çš„åˆ†ææ¨¡å¼",
        options=analysis_mode_options,
        index=analysis_mode_options.index(current_mode) if current_mode in analysis_mode_options else 2,
        format_func=lambda x: {
            "text_only": "ğŸ’° ç´”æ–‡å­— (ç¶“æ¿Ÿ) - åƒ…åˆ†ææ–‡å­—å…§å®¹",
            "vision": "ğŸ‘ï¸ åœ–æ–‡åˆ†æ (é«˜éš) - åˆ†ææ•´å¼µæŠ•å½±ç‰‡æˆªåœ–",
            "auto": "ğŸ¤– è‡ªå‹•åˆ¤æ–· - (æ¨è–¦)"
        }.get(x, x),
        horizontal=True
    )
    
    if st.button("ğŸ’¾ å„²å­˜ API è¨­å®š", type="primary"):
        config.set_api_config(
            api_key=new_api_key,
            base_url=new_base_url,
            model_vision=new_model_vision,
            model_text=new_model_text,
            analysis_mode=new_analysis_mode
        )
        st.success("âœ… API è¨­å®šå·²å„²å­˜!")
        st.rerun()
    
    # é¡¯ç¤ºç•¶å‰ç‹€æ…‹
    if current_config['api_key']:
        st.success("âœ… API Key å·²è¨­å®š")
    else:
        st.warning("âš ï¸ å°šæœªè¨­å®š API Key,è«‹è¼¸å…¥å¾Œé»æ“Šã€Œå„²å­˜ã€")
    
    st.markdown("---")
    
    st.subheader("ğŸ“ è³‡æ–™åº«è·¯å¾‘")
    st.code(config.DB_PATH, language="text")
    st.code(config.TOKEN_DB_PATH, language="text")
    
    st.markdown("---")
    
    st.subheader("âš ï¸ å±éšªæ“ä½œ")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ–‡ä»¶", type="secondary"):
        st.warning("æ­¤åŠŸèƒ½å°šæœªå¯¦ä½œ,è«‹æ‰‹å‹•åˆªé™¤è³‡æ–™åº«æª”æ¡ˆ")
