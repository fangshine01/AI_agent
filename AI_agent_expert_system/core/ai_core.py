"""
AI Expert System - AI Core Module
èˆ‡ AI API (OpenAI/Compatible) çš„æ•´åˆ
æ”¯æ´è‡ªè¨‚ API ç«¯é»ï¼ˆç›´æ¥ HTTP è«‹æ±‚æ¨¡å¼ï¼‰
"""

import base64
import logging
import httpx
from typing import List, Dict
from tenacity import retry, stop_after_attempt, wait_exponential

import config

logger = logging.getLogger(__name__)


def encode_image_to_base64(image_path: str) -> str:
    """å°‡åœ–ç‰‡ç·¨ç¢¼ç‚º base64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def _call_chat_api(messages: List[Dict], model: str = None, temperature: float = 0.3, max_tokens: int = None,
                  api_key: str = None, base_url: str = None) -> str:
    """
    å‘¼å« Chat Completions APIï¼ˆæ¨™æº– OpenAI æ ¼å¼ï¼‰
    
    Args:
        messages: å°è©±è¨Šæ¯åˆ—è¡¨
        model: æ¨¡å‹åç¨±ï¼ˆå¯é¸ï¼‰
        temperature: æº«åº¦åƒæ•¸
        max_tokens: æœ€å¤§ token æ•¸ï¼ˆå¯é¸ï¼‰
        api_key: API Keyï¼ˆå¯é¸ï¼Œæœªæä¾›å‰‡ä½¿ç”¨ configï¼‰
        base_url: Base URLï¼ˆå¯é¸ï¼Œæœªæä¾›å‰‡ä½¿ç”¨ configï¼‰
    
    Returns:
        str: AI å›æ‡‰å…§å®¹
    """
    # ä½¿ç”¨å‚³å…¥çš„ URL æˆ– config é è¨­å€¼
    url = base_url if base_url else config.BASE_URL
    
    # è‹¥ URL ä¸åŒ…å« /chat/completionsï¼Œè‡ªå‹•è£œä¸Š
    if not url.endswith('/chat/completions'):
        if url.endswith('/'):
            url = url + 'chat/completions'
        else:
            url = url + '/chat/completions'
    
    headers = {
        "Content-Type": "application/json",
    }
    
    # ä½¿ç”¨å‚³å…¥çš„ API Key æˆ– config é è¨­å€¼
    used_api_key = api_key if api_key else config.API_KEY
    if used_api_key:
        headers["Authorization"] = f"Bearer {used_api_key.strip()}"
    
    payload = {
        "messages": messages,
        "temperature": temperature,
    }
    
    # è‹¥æœ‰æŒ‡å®š modelï¼ŒåŠ å…¥ payload
    if model:
        payload["model"] = model
    
    # è‹¥æœ‰æŒ‡å®š max_tokensï¼ŒåŠ å…¥ payload
    if max_tokens:
        payload["max_tokens"] = max_tokens
    
    logger.debug(f"ğŸ“¡ API è«‹æ±‚: {url}")
    
    try:
        with httpx.Client(timeout=60.0) as client:
            logger.info(f"ğŸ“¤ ç™¼é€è«‹æ±‚åˆ°: {url}")
            logger.debug(f"ğŸ“¤ è«‹æ±‚ Headers: {headers}")
            logger.debug(f"ğŸ“¤ è«‹æ±‚ Payload: {payload}")
            
            response = client.post(url, json=payload, headers=headers)
            
            # å…ˆè¨˜éŒ„å›æ‡‰ï¼Œå†æª¢æŸ¥ç‹€æ…‹
            logger.info(f"ğŸ“¥ å›æ‡‰ç‹€æ…‹: {response.status_code}")
            logger.debug(f"ğŸ“¥ å›æ‡‰å…§å®¹: {response.text[:500] if response.text else '(ç©º)'}")
            
            response.raise_for_status()
            
            data = response.json()
            
            # æå– Token ä½¿ç”¨è³‡è¨Š
            usage = data.get('usage', {})
            token_info = {
                'prompt_tokens': usage.get('prompt_tokens', 0),
                'completion_tokens': usage.get('completion_tokens', 0),
                'total_tokens': usage.get('total_tokens', 0)
            }
            
            # å˜—è©¦å¾æ¨™æº– OpenAI æ ¼å¼è§£æ
            content = None
            if "choices" in data and len(data["choices"]) > 0:
                content = data["choices"][0]["message"]["content"]
            # è‹¥æ ¼å¼ä¸åŒï¼Œå˜—è©¦å…¶ä»–å¸¸è¦‹æ ¼å¼
            elif "content" in data:
                content = data["content"]
            elif "response" in data:
                content = data["response"]
            elif "message" in data:
                content = data["message"]
            else:
                # è‹¥éƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›åŸå§‹ JSON
                logger.warning(f"âš ï¸ ç„¡æ³•è§£æ API å›æ‡‰æ ¼å¼: {data}")
                content = str(data)
            
            return content, token_info
            
    except httpx.HTTPStatusError as e:
        logger.error(f"âŒ API HTTP éŒ¯èª¤: {e.response.status_code}")
        logger.error(f"âŒ éŒ¯èª¤å›æ‡‰å…§å®¹: {e.response.text}")
        raise
    except Exception as e:
        logger.error(f"âŒ API å‘¼å«å¤±æ•—: {e}")
        raise


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def analyze_slide(
    text: str,
    image_paths: List[str] = None,
    user_focus: str = "",
    api_mode: str = "auto",
    api_key: str = None,
    base_url: str = None,
    text_model: str = None,
    vision_model: str = None
) -> tuple:
    """
    åˆ†æå–®å¼µæŠ•å½±ç‰‡ï¼Œè¿”å›çµæ§‹åŒ–çš„çŸ¥è­˜æ‘˜è¦
    
    Args:
        text: æŠ•å½±ç‰‡æ–‡å­—å…§å®¹
        image_paths: åœ–ç‰‡è·¯å¾‘åˆ—è¡¨ (å¯é¸)
        user_focus: ä½¿ç”¨è€…é—œæ³¨é»
        api_mode: "text_only", "vision", "auto"
        api_key: API Key(å¯é¸)
        base_url: Base URL(å¯é¸)
        text_model: æ–‡å­—æ¨¡å‹åç¨± (å¯é¸,é è¨­ä½¿ç”¨ config.MODEL_TEXT)
        vision_model: è¦–è¦ºæ¨¡å‹åç¨± (å¯é¸,é è¨­ä½¿ç”¨ config.MODEL_VISION)
    
    Returns:
        tuple: (AI åˆ†æå¾Œçš„çµæ§‹åŒ–å…§å®¹, Token ä½¿ç”¨è³‡è¨Š)
    """
    # è™•ç† image_paths ç‚º None çš„æƒ…æ³
    if image_paths is None:
        image_paths = []
    
    # æ™ºæ…§åˆ¤æ–·ä½¿ç”¨å“ªç¨® API
    use_vision = (api_mode == "vision") or (api_mode == "auto" and len(image_paths) > 0)
    
    if use_vision and len(image_paths) > 0:
        return _analyze_with_vision(
            text, image_paths, user_focus, 
            api_key=api_key, base_url=base_url, model=vision_model
        )
    else:
        return _analyze_text_only(
            text, user_focus, 
            api_key=api_key, base_url=base_url, model=text_model
        )


def _analyze_text_only(text: str, user_focus: str = "", api_key: str = None, base_url: str = None, model: str = None) -> str:
    """ä½¿ç”¨ç´”æ–‡å­— API åˆ†æ"""
    if not text.strip():
        return "", {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
    
    prompt = f"""è«‹åˆ†æä»¥ä¸‹æŠ•å½±ç‰‡å…§å®¹ï¼Œæå–é‡é»è³‡è¨Šï¼š

ã€æŠ•å½±ç‰‡æ–‡å­—ã€‘
{text}

{f'ã€ä½¿ç”¨è€…é—œæ³¨é»ã€‘{user_focus}' if user_focus else ''}

ã€è¦æ±‚ã€‘
1. æå–é—œéµè³‡è¨Šä¸¦çµæ§‹åŒ–è¼¸å‡º
2. ä¿ç•™é‡è¦æ•¸æ“šã€äººåã€å°ˆæœ‰åè©
3. è‹¥æœ‰æ¸…å–®æˆ–æ­¥é©Ÿï¼Œè«‹æ•´ç†æˆæ¢åˆ—å¼

è«‹è¼¸å‡ºçµæ§‹åŒ–çš„çŸ¥è­˜æ‘˜è¦ï¼š"""

    try:
        used_model = model if model else config.MODEL_TEXT
        logger.debug(f"ğŸ”¤ ä½¿ç”¨æ–‡å­— API: {used_model}")
        result, usage = _call_chat_api(
            messages=[{"role": "user", "content": prompt}],
            model=used_model,
            temperature=0.3,
            api_key=api_key,
            base_url=base_url
        )
        
        logger.debug(f"âœ… æ–‡å­—åˆ†æå®Œæˆï¼Œé•·åº¦: {len(result)}, Tokens: {usage['total_tokens']}")
        return result, usage
        
    except Exception as e:
        logger.error(f"âŒ æ–‡å­— API å‘¼å«å¤±æ•—: {e}")
        return text, {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}  # é™ç´šï¼šè¿”å›åŸå§‹æ–‡å­—


def _analyze_with_vision(text: str, image_paths: List[str], user_focus: str = "", api_key: str = None, base_url: str = None, model: str = None) -> str:
    """ä½¿ç”¨ Vision API åˆ†æ"""
    content_parts = [
        {
            "type": "text",
            "text": f"""è«‹åˆ†æé€™å¼µæŠ•å½±ç‰‡ï¼Œæ•´åˆæ–‡å­—èˆ‡åœ–ç‰‡å…§å®¹ï¼š

ã€æŠ•å½±ç‰‡æ–‡å­—ã€‘
{text if text else '(ç„¡æ–‡å­—)'}

{f'ã€ä½¿ç”¨è€…é—œæ³¨é»ã€‘{user_focus}' if user_focus else ''}

ã€è¦æ±‚ã€‘
1. è‹¥æœ‰æµç¨‹åœ–ï¼Œè«‹å˜—è©¦è½‰ç‚º Mermaid Markdown æ ¼å¼
2. è‹¥æœ‰åœ–è¡¨ï¼Œè«‹æå–é—œéµæ•¸æ“š
3. æ•´åˆæ‰€æœ‰è³‡è¨Šï¼Œè¼¸å‡ºçµæ§‹åŒ–çš„çŸ¥è­˜æ‘˜è¦

è«‹è¼¸å‡ºçµæ§‹åŒ–å…§å®¹ï¼š"""
        }
    ]
    
    # åŠ å…¥åœ–ç‰‡
    for img_path in image_paths[:5]:  # é™åˆ¶æœ€å¤š 5 å¼µåœ–ç‰‡
        try:
            img_base64 = encode_image_to_base64(img_path)
            img_ext = img_path.split('.')[-1].lower()
            
            content_parts.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{img_ext};base64,{img_base64}"
                }
            })
        except Exception as e:
            logger.warning(f"åœ–ç‰‡ç·¨ç¢¼å¤±æ•— {img_path}: {e}")
    
    try:
        used_model = model if model else config.MODEL_VISION
        logger.debug(f"ğŸ–¼ï¸ ä½¿ç”¨ Vision API: {used_model}, {len(image_paths)} åœ–ç‰‡")
        result, usage = _call_chat_api(
            messages=[{"role": "user", "content": content_parts}],
            model=used_model,
            temperature=0.3,
            max_tokens=1500,
            api_key=api_key,
            base_url=base_url
        )
        
        logger.debug(f"âœ… Vision åˆ†æå®Œæˆ,é•·åº¦: {len(result)}, Tokens: {usage['total_tokens']}")
        return result, usage
        
    except Exception as e:
        logger.error(f"âŒ Vision API å‘¼å«å¤±æ•—: {e}")
        # é™ç´š:ä½¿ç”¨ç´”æ–‡å­—æ¨¡å¼
        return _analyze_text_only(text, user_focus, api_key=api_key, base_url=base_url, model=None)


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def get_embedding(text: str, api_key: str = None, base_url: str = None) -> tuple:
    """
    å–å¾—æ–‡å­—çš„ Embedding å‘é‡
    
    Args:
        text: è¼¸å…¥æ–‡å­—
        api_key: API Key (å„ªå…ˆä½¿ç”¨)
        base_url: Base URL (å„ªå…ˆä½¿ç”¨)
        
    Returns:
        tuple: (embedding_vector, usage_dict)
    """
    try:
        if not text:
            return [], {'total_tokens': 0}
            
        text = text.replace("\n", " ")
        if len(text) > 8000:
            text = text[:8000]
            
        # æ±ºå®š API Config
        used_api_key = api_key if api_key else config.API_KEY
        used_base_url = base_url if base_url else config.BASE_URL
        
        if not used_api_key:
            logger.error("âŒ æœªæä¾› API Keyï¼Œç„¡æ³•å‘¼å« Embedding API")
            raise ValueError("API Key is missing")
            
        client = httpx.Client(timeout=30.0)
        
        response = client.post(
            f"{used_base_url}/embeddings",
            headers={
                "Authorization": f"Bearer {used_api_key.strip()}",
                "Content-Type": "application/json"
            },
            json={
                "input": text,
                "model": config.EMBEDDING_MODEL
            }
        )
        response.raise_for_status()
        
        data = response.json()
        embedding = data['data'][0]['embedding']
        usage = data.get('usage', {'total_tokens': 0})
        
        return embedding, usage
        
    except Exception as e:
        logger.error(f"âŒ Embedding API å‘¼å«å¤±æ•—: {e}")
        raise


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def chat_response(
    question: str,
    context_slides: List[Dict],
    conversation_history: List[Dict] = None,
    api_key: str = None,
    base_url: str = None
) -> Dict:
    """
    åŸºæ–¼æª¢ç´¢åˆ°çš„å…§å®¹å›ç­”ä½¿ç”¨è€…å•é¡Œ
    
    Args:
        question: ä½¿ç”¨è€…å•é¡Œ
        context_slides: æª¢ç´¢åˆ°çš„æŠ•å½±ç‰‡åˆ—è¡¨ [{file_path, file_name, page_num, content}, ...]
        conversation_history: å°è©±æ­·å²
        api_key: API Key(å¯é¸)
        base_url: Base URL(å¯é¸)
    
    Returns:
        {
            'answer': str,
            'sources': [
                {'file': 'xxx.pptx', 'page': 5},
                ...
            ]
        }
    """
    if conversation_history is None:
        conversation_history = []
    
    # å»ºæ§‹ä¸Šä¸‹æ–‡
    context_text = "\n\n".join([
        f"ã€ä¾†æºï¼š{slide['file_name']} - ç¬¬ {slide['page_num']} é ã€‘\n{slide['content']}"
        for slide in context_slides
    ])
    
    system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©ä½¿ç”¨è€…å¾ PPT ç°¡å ±ä¸­æ‰¾åˆ°è³‡è¨Šã€‚

è«‹æ ¹æ“šæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”å•é¡Œï¼Œä¸¦éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
1. åƒ…æ ¹æ“šæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”
2. è‹¥ä¸Šä¸‹æ–‡ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œæ˜ç¢ºå‘ŠçŸ¥ä½¿ç”¨è€…
3. å¼•ç”¨æ™‚è«‹æåŠä¾†æºï¼ˆæª”æ¡ˆåç¨±èˆ‡é ç¢¼ï¼‰
4. å›ç­”è¦ç°¡æ½”æ¸…æ™°"""

    user_prompt = f"""ã€ä¸Šä¸‹æ–‡è³‡æ–™ã€‘
{context_text}

ã€ä½¿ç”¨è€…å•é¡Œã€‘
{question}

è«‹æ ¹æ“šä¸Šè¿°ä¸Šä¸‹æ–‡å›ç­”å•é¡Œï¼š"""

    try:
        messages = [{"role": "system", "content": system_prompt}]
        
        # åŠ å…¥å°è©±æ­·å²ï¼ˆæœ€å¤š 5 è¼ªï¼‰
        messages.extend(conversation_history[-10:])
        
        # åŠ å…¥ç•¶å‰å•é¡Œ
        messages.append({"role": "user", "content": user_prompt})
        
        logger.debug(f"ğŸ’¬ å•ç­” API å‘¼å«: {question[:50]}...")
        answer, usage = _call_chat_api(
            messages=messages,
            model=config.MODEL_TEXT,
            temperature=0.5,
            api_key=api_key,
            base_url=base_url
        )
        
        # æ•´ç†ä¾†æº
        sources = [
            {'file': slide['file_name'], 'page': slide['page_num']}
            for slide in context_slides
        ]
        
        logger.debug(f"âœ… å•ç­”å®Œæˆï¼Œä¾†æºæ•¸: {len(sources)}, Tokens: {usage['total_tokens']}")
        
        # å›å‚³ tuple æ ¼å¼ (response_text, usage) ä»¥ç¬¦åˆ Parser çš„æœŸå¾…
        return answer, usage
        
    except Exception as e:
        logger.error(f"âŒ å•ç­” API å‘¼å«å¤±æ•—: {e}")
        return f"æŠ±æ­‰ï¼Œç™¼ç”ŸéŒ¯èª¤:{str(e)}", {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def extract_keywords(text: str, api_key: str = None, base_url: str = None) -> List[str]:
    """
    å¾æ–‡å­—ä¸­æå–é—œéµå­—
    
    Args:
        text: è¼¸å…¥æ–‡å­—
        api_key: API Key (å¯é¸)
        base_url: Base URL (å¯é¸)
    
    Returns:
        List[str]: é—œéµå­—åˆ—è¡¨
    """
    if not text or len(text) < 10:
        return []
        
    prompt = f"""è«‹å¾ä»¥ä¸‹æŠ€è¡“æ–‡ä»¶ä¸­æå– 3-5 å€‹é—œéµå­—ï¼š

ã€æ–‡ä»¶å…§å®¹ã€‘
{text[:2000]}... (ä¸‹ç•¥)

ã€è¦æ±‚ã€‘
1. å°ˆæ³¨æ–¼ï¼šç”¢å“å‹è™Ÿ(å¦‚ N706)ã€æ©Ÿå°ç«™é»(å¦‚ Station A)ã€Defect Code(å¦‚ E001)ã€å°ˆæœ‰åè©
2. åªè¼¸å‡ºé—œéµå­—ï¼Œç”¨é€—è™Ÿåˆ†éš”
3. ä¸è¦è¼¸å‡ºä»»ä½•è§£é‡‹æ–‡å­—

é—œéµå­—ï¼š"""

    try:
        result, _ = _call_chat_api(
            messages=[{"role": "user", "content": prompt}],
            model=config.MODEL_TEXT,
            temperature=0.3,
            max_tokens=100,
            api_key=api_key,
            base_url=base_url
        )
        
        # æ¸…ç†çµæœ
        if result:
            keywords = [k.strip() for k in result.replace("ã€", ",").split(",") if k.strip()]
            return keywords
        return []
        
    except Exception as e:
        logger.error(f"âŒ é—œéµå­—æå–å¤±æ•—: {e}")
        return []


# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    print("æ¸¬è©¦ AI API é€£æ¥...")
    
    test_text = "é€™æ˜¯ä¸€å€‹æ¸¬è©¦æŠ•å½±ç‰‡ï¼ŒåŒ…å«æ©Ÿå™¨å­¸ç¿’çš„åŸºæœ¬æ¦‚å¿µã€‚"
    result = analyze_slide(test_text, [], api_mode="text_only")
    print(f"çµæœ: {result[:200]}...")
